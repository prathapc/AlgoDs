Graph:
DFS::
traverse all nodes O(V+E)
shortest path O(V-1)! => when source is connected to all other vertices
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
Polynomial complexity:-
---------------------
http://mathwiki.cs.ut.ee/asymptotics/05_polynomial_complexity

The main aim of computer science is develop efficient algorithms for different problems.
However, the question what is efficient is not so straightforward.
Engineers who program low-level operating system routines try to shave off any assembler level instruction,
while scientists who conduct large numerical simulations try to devise algorithms with sub-quadratic complexity.
The most liberal definition of efficiency is used by theoretical computer scientists, who consider all polynomial time algorithms as efficient.

Definition:- An algorithm is said to have polynomial time complexity if its worst-case running time
Tworst(n) for an input of size n is upper bounded by a polynomial p(n) for large enough nâ‰¥n0.

Many widely used algorithms have polynomial time complexity (like our algorithms readNumbers1 and readNumbers2, quicksort,
insertion sort, binary search etc. etc.).

Examples of algorithms with non-polynomial time complexity are all kinds of brute-force algorithms
that look through all possible configurations. For example, looking through all the subsets of a set of size n takes time O(2n),
looking through all possible ways of totally ordering n elements takes time O(n!).
------------------------------------------------------------------------------------------------------------------------------------------------------------

Note:- The problem with permutations is that there is a much more permutations than subsets, N! grows up much faster than 2^N

